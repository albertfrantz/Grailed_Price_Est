{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grailed Webscrape Part 1: Designer Links\n",
    "\n",
    "Grailed is an especially difficult website to webscrape. Original I hoped to just scrape grailed.com/sold but I quickly discovered one could only scroll far enough to collect about 800 sold items. To overcome the issue I decided to collect sold items on grailed with the following steps.\n",
    "\n",
    "1. scrape grailed for the links to all the designers on grailed (~6,000 total brands).\n",
    "2. Go to the sold section for each of those designers.\n",
    "3. For each designer, collect the link to each individual item.\n",
    "4. For each item gather the essential components that can be used for modeling.\n",
    "\n",
    "This first notebook completes the first two steps of the webscraping task. First by collecting links to each of the designer pages on grailed and next by collecting the sold pages for each of those designers.\n",
    "\n",
    "Help was recieved from the following post: https://medium.com/@mike_liu/scraping-grailed-8501eef914a8\n",
    "\n",
    "Although the notebooks that follow have been heavily adapted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Designer Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a base url for where to find all the designers on grailed\n",
    "base_url = \"https://www.grailed.com/designers/\"\n",
    "\n",
    "# open up chrome\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "driver = webdriver.Chrome(\"C:/Users/alber/Documents/chromedriver.exe\",options=chrome_options) # replace webdrive location with ones own\n",
    "driver.get(base_url)\n",
    "\n",
    "# wait 30 sec will quit if takes over 30 seconds\n",
    "timeout = 30\n",
    "try:\n",
    "    WebDriverWait(driver, timeout).until(EC.visibility_of_element_located((By.XPATH, \"//div[@id='app']\")))\n",
    "except TimeoutException:\n",
    "    print(\"Timed out\")\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6140"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gathering all links on designer page\n",
    "results = driver.find_elements_by_xpath(\"//a[@href]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.grailed.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.grailed.com/shop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.grailed.com/sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.grailed.com/drycleanonly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.grailed.com/users/sign_up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6135</th>\n",
       "      <td>https://www.facebook.com/grailed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6136</th>\n",
       "      <td>https://www.twitter.com/grailed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6137</th>\n",
       "      <td>https://www.youtube.com/channel/UCrcycxtz_yoAf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6138</th>\n",
       "      <td>https://www.linkedin.com/company/grailed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6139</th>\n",
       "      <td>https://www.grailed.com/trust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6140 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Link\n",
       "0                              https://www.grailed.com/\n",
       "1                          https://www.grailed.com/shop\n",
       "2                          https://www.grailed.com/sell\n",
       "3                  https://www.grailed.com/drycleanonly\n",
       "4                 https://www.grailed.com/users/sign_up\n",
       "...                                                 ...\n",
       "6135                   https://www.facebook.com/grailed\n",
       "6136                    https://www.twitter.com/grailed\n",
       "6137  https://www.youtube.com/channel/UCrcycxtz_yoAf...\n",
       "6138           https://www.linkedin.com/company/grailed\n",
       "6139                      https://www.grailed.com/trust\n",
       "\n",
       "[6140 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a list of all the links \n",
    "Link =[]\n",
    "for result in results:\n",
    "        link = result.get_attribute(\"href\") # grabbing the link attribute\n",
    "        Link.append(link)\n",
    "\n",
    "# Turn the Links into a DataFrame\n",
    "ItemDF=pd.DataFrame(Link,columns=['Link'])\n",
    "ItemDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering out links that are not designer page links\n",
    "ItemDF = ItemDF[ItemDF['Link'].str.contains(\"designers/\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6028"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in total we have 6,028 designers to scrape\n",
    "len(ItemDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the brand_links as a csv\n",
    "ItemDF.to_csv('brand_links.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Getting to the Sold Page for Each Designer\n",
    "\n",
    "This step may seem like an uneccessary one. For example you may think that going from the current listings of Prada to the sold listings of prada would be as simple as changing the designer link from https://www.grailed.com/designers/prada to https://www.grailed.com/sold/prada this, however is not the case. Instead the true link to the prada sold listings is https://www.grailed.com/sold/taPPoyeJEw. There is no simple way to access what exactly the sold link may be for each designer so they must be gathered by the following proccess:\n",
    "\n",
    "1. access the designer page\n",
    "2. click on show only\n",
    "3. close the login pop-up\n",
    "4. click on the sold box\n",
    "5. wait for page to load and gather the link\n",
    "\n",
    "Because this process is slow I broke up the process of gather the sold links for the 6,000 designers into groups of 1,000 incase my computer crashes (which it did multiple times)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "# list of sold links to be appended to\n",
    "sold_links_1000 = []\n",
    "# count will be used to get an idea of where i am in the scraping process\n",
    "count = 0\n",
    "\n",
    "# going through first 1,000 designer links\n",
    "for link in ItemDF['Link'][:1000]:\n",
    "    # will open the desinger link\n",
    "    base_url = link  \n",
    "    # open up chrome. \n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"--start-maximized\") # using full screan\n",
    "    driver = webdriver.Chrome(\"C:/Users/alber/Documents/chromedriver.exe\",options=chrome_options) # replace webdrive location with ones own\n",
    "    driver.get(base_url)\n",
    "    # wait 30 sec\n",
    "    timeout = 30\n",
    "    try:\n",
    "        WebDriverWait(driver, timeout).until(EC.visibility_of_element_located((By.XPATH, \"//div[@id='__next']\")))\n",
    "    except TimeoutException:\n",
    "        print(\"Timed out waiting for page to load\")\n",
    "        driver.close()\n",
    "        continue\n",
    "    \n",
    "    WebDriverWait(driver, 10)    \n",
    "    \n",
    "    try:\n",
    "        element = driver.find_elements_by_xpath(\"//*[contains(text(),'Show Only')]\") # finding show only button \n",
    "        element[0].click(); # click show only\n",
    "    except:\n",
    "        driver.close()\n",
    "        continue\n",
    "        \n",
    "    driver.implicitly_wait(1)\n",
    "    \n",
    "    try:\n",
    "        elem = driver.find_element_by_xpath(\"//div[@class='UsersAuthentication']\") # user login window will pop up\n",
    "        ac = ActionChains(driver)\n",
    "        ac.move_to_element(elem).move_by_offset(250, 0).click().perform() # clicking away from login window\n",
    "    except:\n",
    "        driver.close()\n",
    "        print('failed')\n",
    "        continue\n",
    "    \n",
    "    driver.implicitly_wait(1)\n",
    "    \n",
    "    try:\n",
    "        element = driver.find_elements_by_xpath(\"//*[contains(text(),'Show Only')]\") # finding show only button again\n",
    "        element[0].click(); # clicking now that pop-up is away\n",
    "    except:\n",
    "        driver.close()\n",
    "        continue\n",
    "    \n",
    "    driver.implicitly_wait(1)\n",
    "    \n",
    "    try:\n",
    "        element = driver.find_elements_by_xpath(\"//input[@id='sold-filter']\") # finding sold box\n",
    "        element[0].click(); # click sold box\n",
    "    except:\n",
    "        driver.close()\n",
    "        continue\n",
    "    \n",
    "    driver.implicitly_wait(1)   \n",
    "    \n",
    "    try:\n",
    "        sold_link = driver.current_url # getting current url which is the sold link for the designer\n",
    "        sold_links_1000.append(sold_link) # appending sold link\n",
    "    except:\n",
    "        driver.close()\n",
    "        continue\n",
    "    \n",
    "    driver.close()\n",
    "    \n",
    "    count += 1\n",
    "    \n",
    "    if count%10 == 0:\n",
    "        print(count)\n",
    "\n",
    "# creating df and exporting first 1000 sold links\n",
    "SoldDF_1000=pd.DataFrame(sold_links_1000,columns=['Link'])\n",
    "SoldDF_1000.to_csv('sold_links_1000.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This same process is then repeated 5 more times with the last 5,000 designers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "# list of sold links\n",
    "sold_links_2000 = []\n",
    "count = 0\n",
    "for link in ItemDF['Link'][1000:2000]:\n",
    "    # Set a URL\n",
    "    base_url = link  \n",
    "    # open up chrome. \n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"--start-maximized\")\n",
    "    driver = webdriver.Chrome(\"C:/Users/alber/Documents/chromedriver.exe\",options=chrome_options)\n",
    "    driver.get(base_url)\n",
    "    # wait 30 sec\n",
    "    timeout = 30\n",
    "    try:\n",
    "        WebDriverWait(driver, timeout).until(EC.visibility_of_element_located((By.XPATH, \"//div[@id='__next']\")))\n",
    "    except TimeoutException:\n",
    "        print(\"Timed out waiting for page to load\")\n",
    "        driver.close()\n",
    "        continue\n",
    "    \n",
    "    WebDriverWait(driver, 10)    \n",
    "    \n",
    "    try:\n",
    "        element = driver.find_elements_by_xpath(\"//*[contains(text(),'Show Only')]\")\n",
    "        element[0].click();\n",
    "    except:\n",
    "        driver.close()\n",
    "        continue\n",
    "        \n",
    "    driver.implicitly_wait(1)\n",
    "    \n",
    "    try:\n",
    "        elem = driver.find_element_by_xpath(\"//div[@class='UsersAuthentication']\")\n",
    "        ac = ActionChains(driver)\n",
    "        ac.move_to_element(elem).move_by_offset(250, 0).click().perform()\n",
    "    except:\n",
    "        driver.close()\n",
    "        print('failed')\n",
    "        continue\n",
    "    \n",
    "    driver.implicitly_wait(1)\n",
    "    \n",
    "    try:\n",
    "        element = driver.find_elements_by_xpath(\"//*[contains(text(),'Show Only')]\")\n",
    "        element[0].click();\n",
    "    except:\n",
    "        driver.close()\n",
    "        continue\n",
    "    \n",
    "    driver.implicitly_wait(1)\n",
    "    \n",
    "    try:\n",
    "        element = driver.find_elements_by_xpath(\"//input[@id='sold-filter']\")\n",
    "        element[0].click();\n",
    "    except:\n",
    "        driver.close()\n",
    "        continue\n",
    "    \n",
    "    driver.implicitly_wait(1)   \n",
    "    \n",
    "    try:\n",
    "        sold_link = driver.current_url\n",
    "        sold_links_2000.append(sold_link)\n",
    "    except:\n",
    "        driver.close()\n",
    "        continue\n",
    "    \n",
    "    driver.close()\n",
    "    \n",
    "    count += 1\n",
    "    \n",
    "    if count%10 == 0:\n",
    "        print(count)\n",
    "        \n",
    "SoldDF_2000=pd.DataFrame(sold_links_2000,columns=['Link'])\n",
    "SoldDF_2000.to_csv('sold_links_2000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n"
     ]
    }
   ],
   "source": [
    "# list of sold links\n",
    "sold_links_3000_2 = []\n",
    "count = 0\n",
    "for link in ItemDF['Link'][2269:3000]:\n",
    "    # Set a URL\n",
    "    base_url = link  \n",
    "    # open up chrome\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"--start-maximized\")\n",
    "    driver = webdriver.Chrome(\"C:/Users/alber/Documents/chromedriver.exe\",options=chrome_options)\n",
    "    driver.get(base_url)\n",
    "    # wait 30 sec\n",
    "    timeout = 30\n",
    "    try:\n",
    "        WebDriverWait(driver, timeout).until(EC.visibility_of_element_located((By.XPATH, \"//div[@id='__next']\")))\n",
    "    except TimeoutException:\n",
    "        print(\"Timed out waiting for page to load\")\n",
    "        driver.close()\n",
    "        continue\n",
    "    \n",
    "    WebDriverWait(driver, 10)    \n",
    "    \n",
    "    try:\n",
    "        element = driver.find_elements_by_xpath(\"//*[contains(text(),'Show Only')]\")\n",
    "        element[0].click();\n",
    "    except:\n",
    "        driver.close()\n",
    "        continue\n",
    "        \n",
    "    driver.implicitly_wait(1)\n",
    "    \n",
    "    try:\n",
    "        elem = driver.find_element_by_xpath(\"//div[@class='UsersAuthentication']\")\n",
    "        ac = ActionChains(driver)\n",
    "        ac.move_to_element(elem).move_by_offset(250, 0).click().perform()\n",
    "    except:\n",
    "        driver.close()\n",
    "        print('failed')\n",
    "        continue\n",
    "    \n",
    "    driver.implicitly_wait(1)\n",
    "    \n",
    "    try:\n",
    "        element = driver.find_elements_by_xpath(\"//*[contains(text(),'Show Only')]\")\n",
    "        element[0].click();\n",
    "    except:\n",
    "        driver.close()\n",
    "        continue\n",
    "    \n",
    "    driver.implicitly_wait(1)\n",
    "    \n",
    "    try:\n",
    "        element = driver.find_elements_by_xpath(\"//input[@id='sold-filter']\")\n",
    "        element[0].click();\n",
    "    except:\n",
    "        driver.close()\n",
    "        continue\n",
    "    \n",
    "    driver.implicitly_wait(1)   \n",
    "    \n",
    "    try:\n",
    "        sold_link = driver.current_url\n",
    "        sold_links_3000_2.append(sold_link)\n",
    "    except:\n",
    "        driver.close()\n",
    "        continue\n",
    "    \n",
    "    driver.close()\n",
    "    \n",
    "    count += 1\n",
    "    \n",
    "    if count%10 == 0:\n",
    "        print(count)\n",
    "\n",
    "# computer decided to stop at one point so needed to append the two lists        \n",
    "sold_links_3000_total = sold_links_3000+sold_links_3000_2\n",
    "SoldDF_3000=pd.DataFrame(sold_links_3000_total,columns=['Link'])\n",
    "SoldDF_3000.to_csv('sold_links_3000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n"
     ]
    }
   ],
   "source": [
    "# list of sold links\n",
    "sold_links_4000_2 = []\n",
    "count = 0\n",
    "for link in ItemDF['Link'][3184:4000]:\n",
    "    # Set a URL\n",
    "    base_url = link  \n",
    "    # open up chrome.\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"--start-maximized\")\n",
    "    driver = webdriver.Chrome(\"C:/Users/alber/Documents/chromedriver.exe\",options=chrome_options)\n",
    "    driver.get(base_url)\n",
    "    # wait 30 sec\n",
    "    timeout = 30\n",
    "    try:\n",
    "        WebDriverWait(driver, timeout).until(EC.visibility_of_element_located((By.XPATH, \"//div[@id='__next']\")))\n",
    "    except TimeoutException:\n",
    "        print(\"Timed out waiting for page to load\")\n",
    "        driver.close()\n",
    "        continue\n",
    "    \n",
    "    WebDriverWait(driver, 10)    \n",
    "    \n",
    "    try:\n",
    "        element = driver.find_elements_by_xpath(\"//*[contains(text(),'Show Only')]\")\n",
    "        element[0].click();\n",
    "    except:\n",
    "        driver.close()\n",
    "        continue\n",
    "        \n",
    "    driver.implicitly_wait(1)\n",
    "    \n",
    "    try:\n",
    "        elem = driver.find_element_by_xpath(\"//div[@class='UsersAuthentication']\")\n",
    "        ac = ActionChains(driver)\n",
    "        ac.move_to_element(elem).move_by_offset(250, 0).click().perform()\n",
    "    except:\n",
    "        driver.close()\n",
    "        print('failed')\n",
    "        continue\n",
    "    \n",
    "    driver.implicitly_wait(1)\n",
    "    \n",
    "    try:\n",
    "        element = driver.find_elements_by_xpath(\"//*[contains(text(),'Show Only')]\")\n",
    "        element[0].click();\n",
    "    except:\n",
    "        driver.close()\n",
    "        continue\n",
    "    \n",
    "    driver.implicitly_wait(1)\n",
    "    \n",
    "    try:\n",
    "        element = driver.find_elements_by_xpath(\"//input[@id='sold-filter']\")\n",
    "        element[0].click();\n",
    "    except:\n",
    "        driver.close()\n",
    "        continue\n",
    "    \n",
    "    driver.implicitly_wait(1)   \n",
    "    \n",
    "    try:\n",
    "        sold_link = driver.current_url\n",
    "        sold_links_4000_2.append(sold_link)\n",
    "    except:\n",
    "        driver.close()\n",
    "        continue\n",
    "    \n",
    "    driver.close()\n",
    "    \n",
    "    count += 1\n",
    "    \n",
    "    if count%10 == 0:\n",
    "        print(count)\n",
    "        \n",
    "sold_links_4000_total = sold_links_4000+sold_links_4000_2        \n",
    "SoldDF_4000=pd.DataFrame(sold_links_4000_total,columns=['Link'])\n",
    "SoldDF_4000.to_csv('sold_links_4000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "# list of sold links\n",
    "sold_links_5000_2 = []\n",
    "count = 0\n",
    "for link in ItemDF['Link'][4700:5000]:\n",
    "    # Set a URL\n",
    "    base_url = link  \n",
    "    # open up chrome.\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"--start-maximized\")\n",
    "    driver = webdriver.Chrome(\"C:/Users/alber/Documents/chromedriver.exe\",options=chrome_options)\n",
    "    driver.get(base_url)\n",
    "    # wait 30 sec\n",
    "    timeout = 30\n",
    "    try:\n",
    "        WebDriverWait(driver, timeout).until(EC.visibility_of_element_located((By.XPATH, \"//div[@id='__next']\")))\n",
    "    except TimeoutException:\n",
    "        print(\"Timed out waiting for page to load\")\n",
    "        driver.close()\n",
    "        continue\n",
    "    \n",
    "    WebDriverWait(driver, 10)    \n",
    "    \n",
    "    try:\n",
    "        element = driver.find_elements_by_xpath(\"//*[contains(text(),'Show Only')]\")\n",
    "        element[0].click();\n",
    "    except:\n",
    "        driver.close()\n",
    "        continue\n",
    "        \n",
    "    driver.implicitly_wait(1)\n",
    "    \n",
    "    try:\n",
    "        elem = driver.find_element_by_xpath(\"//div[@class='UsersAuthentication']\")\n",
    "        ac = ActionChains(driver)\n",
    "        ac.move_to_element(elem).move_by_offset(250, 0).click().perform()\n",
    "    except:\n",
    "        driver.close()\n",
    "        print('failed')\n",
    "        continue\n",
    "    \n",
    "    driver.implicitly_wait(1)\n",
    "    \n",
    "    try:\n",
    "        element = driver.find_elements_by_xpath(\"//*[contains(text(),'Show Only')]\")\n",
    "        element[0].click();\n",
    "    except:\n",
    "        driver.close()\n",
    "        continue\n",
    "    \n",
    "    driver.implicitly_wait(1)\n",
    "    \n",
    "    try:\n",
    "        element = driver.find_elements_by_xpath(\"//input[@id='sold-filter']\")\n",
    "        element[0].click();\n",
    "    except:\n",
    "        driver.close()\n",
    "        continue\n",
    "    \n",
    "    driver.implicitly_wait(1)   \n",
    "    \n",
    "    try:\n",
    "        sold_link = driver.current_url\n",
    "        sold_links_5000_2.append(sold_link)\n",
    "    except:\n",
    "        driver.close()\n",
    "        continue\n",
    "    \n",
    "    driver.close()\n",
    "    \n",
    "    count += 1\n",
    "    \n",
    "    if count%10 == 0:\n",
    "        print(count)\n",
    "\n",
    "sold_links_5000_total = sold_links_5000+sold_links_5000_2                \n",
    "SoldDF_5000=pd.DataFrame(sold_links_5000_total,columns=['Link'])\n",
    "SoldDF_5000.to_csv('sold_links_5000_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n"
     ]
    }
   ],
   "source": [
    "# list of sold links\n",
    "sold_links_6000 = []\n",
    "count = 0\n",
    "for link in ItemDF['Link'][5000:]:\n",
    "    # Set a URL\n",
    "    base_url = link  \n",
    "    # open up chrome. \n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"--start-maximized\")\n",
    "    driver = webdriver.Chrome(\"C:/Users/alber/Documents/chromedriver.exe\",options=chrome_options)\n",
    "    driver.get(base_url)\n",
    "    # wait 30 sec\n",
    "    timeout = 30\n",
    "    try:\n",
    "        WebDriverWait(driver, timeout).until(EC.visibility_of_element_located((By.XPATH, \"//div[@id='__next']\")))\n",
    "    except TimeoutException:\n",
    "        print(\"Timed out waiting for page to load\")\n",
    "        driver.close()\n",
    "        continue\n",
    "    \n",
    "    WebDriverWait(driver, 10)    \n",
    "    \n",
    "    try:\n",
    "        element = driver.find_elements_by_xpath(\"//*[contains(text(),'Show Only')]\")\n",
    "        element[0].click();\n",
    "    except:\n",
    "        driver.close()\n",
    "        continue\n",
    "        \n",
    "    driver.implicitly_wait(1)\n",
    "    \n",
    "    try:\n",
    "        elem = driver.find_element_by_xpath(\"//div[@class='UsersAuthentication']\")\n",
    "        ac = ActionChains(driver)\n",
    "        ac.move_to_element(elem).move_by_offset(250, 0).click().perform()\n",
    "    except:\n",
    "        driver.close()\n",
    "        print('failed')\n",
    "        continue\n",
    "    \n",
    "    driver.implicitly_wait(1)\n",
    "    \n",
    "    try:\n",
    "        element = driver.find_elements_by_xpath(\"//*[contains(text(),'Show Only')]\")\n",
    "        element[0].click();\n",
    "    except:\n",
    "        driver.close()\n",
    "        continue\n",
    "    \n",
    "    driver.implicitly_wait(1)\n",
    "    \n",
    "    try:\n",
    "        element = driver.find_elements_by_xpath(\"//input[@id='sold-filter']\")\n",
    "        element[0].click();\n",
    "    except:\n",
    "        driver.close()\n",
    "        continue\n",
    "    \n",
    "    driver.implicitly_wait(1)   \n",
    "    \n",
    "    try:\n",
    "        sold_link = driver.current_url\n",
    "        sold_links_6000.append(sold_link)\n",
    "    except:\n",
    "        driver.close()\n",
    "        continue\n",
    "    \n",
    "    driver.close()\n",
    "    \n",
    "    count += 1\n",
    "    \n",
    "    if count%10 == 0:\n",
    "        print(count)\n",
    "        \n",
    "SoldDF_6000=pd.DataFrame(sold_links_6000,columns=['Link'])\n",
    "SoldDF_6000.to_csv('sold_links_6000.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
