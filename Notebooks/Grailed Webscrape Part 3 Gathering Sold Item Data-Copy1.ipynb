{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grailed Webscrape Part 3: Gathering Sold Item Data\n",
    "\n",
    "Using the links for items sold in the last notebook the following notebook will go through each link (about 300,000 in total) and gather the essential information to be used in model building. Once again due to the length of this scraping process the dataset is divided multiple times and multiple computers were once again used.\n",
    "That essential information gathered here includes:\n",
    "1. Username of poster\n",
    "2. Designer of posting\n",
    "3. SubTitle of posting\n",
    "4. Size of posting\n",
    "5. Color of posting\n",
    "6. Condition of posting\n",
    "7. Category of posting\n",
    "8. FeedbackCount of poster\n",
    "9. Price sold of posting\n",
    "10. Description of posting\n",
    "11. Number of images in the posting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in the sold item links\n",
    "df_1 = pd.read_csv('../Data/Sold_Item_Links/Sold_Items_1.csv', index_col=[0])\n",
    "df_1.drop_duplicates(inplace=True) # dropping any potential duplicates\n",
    "\n",
    "df_2 = pd.read_csv('../Data/Sold_Item_Links/Sold_Items_2.csv', index_col=[0])\n",
    "df_2.drop_duplicates(inplace=True)\n",
    "\n",
    "df_3 = pd.read_csv('../Data/Sold_Item_Links/Sold_Items_3.csv', index_col=[0])\n",
    "df_3.drop_duplicates(inplace=True)\n",
    "\n",
    "df_4 = pd.read_csv('../Data/Sold_Item_Links/Sold_Items_4.csv', index_col=[0])\n",
    "df_4.drop_duplicates(inplace=True)\n",
    "\n",
    "df_5 = pd.read_csv('../Data/Sold_Item_Links/Sold_Items_5.csv', index_col=[0])\n",
    "df_5.drop_duplicates(inplace=True)\n",
    "\n",
    "df_6 = pd.read_csv('../Data/Sold_Item_Links/Sold_Items_6.csv', index_col=[0])\n",
    "df_6.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n",
      "13400\n",
      "13500\n",
      "13600\n",
      "13700\n",
      "13800\n",
      "13900\n",
      "14000\n",
      "14100\n",
      "14200\n",
      "14300\n",
      "14400\n",
      "14500\n",
      "14600\n",
      "14700\n",
      "14800\n",
      "14900\n",
      "15000\n",
      "15100\n",
      "15200\n",
      "15300\n",
      "15400\n",
      "15500\n",
      "15600\n",
      "15700\n",
      "15800\n",
      "15900\n",
      "16000\n",
      "16100\n",
      "16200\n",
      "16300\n",
      "16400\n",
      "16500\n",
      "16600\n",
      "16700\n",
      "16800\n",
      "16900\n",
      "17000\n",
      "17100\n",
      "17200\n",
      "17300\n"
     ]
    }
   ],
   "source": [
    "# empty lists for all the information I want to gather\n",
    "UserName = []\n",
    "Designer = []\n",
    "SubTitle = []\n",
    "SizeColorCond = []\n",
    "Category = []\n",
    "FeedbackCount = []\n",
    "Price = []\n",
    "Description = []\n",
    "NumImages = []\n",
    "Link = []\n",
    "count = 0 \n",
    "\n",
    "# opening chrome\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "driver = webdriver.Chrome(\"C:/Users/alber/Documents/chromedriver.exe\",options=chrome_options) # change with location fo your webdriver\n",
    "driver.get(\"https://www.grailed.com/sold\")\n",
    "# timeout after 30 sec\n",
    "timeout = 30\n",
    "try:\n",
    "    WebDriverWait(driver, timeout).until(EC.visibility_of_element_located((By.XPATH, \"//div[@class='feed-item']\")))\n",
    "except TimeoutException:\n",
    "    print(\"Timed out waiting for page to load\")\n",
    "    driver.quit()\n",
    "\n",
    "# looping through all the links in df_1\n",
    "for link in df_1['Link']:\n",
    "    \n",
    "    count += 1\n",
    "    \n",
    "    if count%100 == 0:\n",
    "        print(count)\n",
    "    \n",
    "    # saving df every 5000 items gathered    \n",
    "    if count%5000 == 0:\n",
    "        item_desc_1 = pd.DataFrame(\n",
    "            {'username': UserName,\n",
    "             'sold_price': Price,\n",
    "             'designer' : Designer,\n",
    "             'category' : Category,\n",
    "             'description': Description,\n",
    "             'sub_title': SubTitle,\n",
    "             'image_count' : NumImages,\n",
    "             'size_color_cond': SizeColorCond,\n",
    "             'feedback_count' : FeedbackCount,\n",
    "             'link' : Link\n",
    "            })\n",
    "        \n",
    "        item_desc_1.to_csv('item_desc_1.csv')  \n",
    "    \n",
    "    try:\n",
    "        driver.get(link)\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    # gathering item designer name\n",
    "    try:\n",
    "        designer=driver.find_elements_by_xpath('//a[@class=\"designer-name\"]')\n",
    "        if len(designer)==2:\n",
    "            Designer.append(f'{designer[0].text} x {designer[1].text}') # if the item is a colloboration between designers\n",
    "        else:\n",
    "            Designer.append(designer[0].text)\n",
    "    except:\n",
    "        Designer.append(\"\")\n",
    "    \n",
    "    # gathering item sub-title\n",
    "    try:\n",
    "        sub_title=driver.find_element_by_xpath('//h1[@class=\"listing-title sub-title\"]').text\n",
    "        SubTitle.append(sub_title)\n",
    "    except:\n",
    "        SubTitle.append(\"\")\n",
    "    \n",
    "    # gathering poster's username\n",
    "    try:\n",
    "        user_name=driver.find_element_by_xpath('//span[@class=\"-username\"]').text\n",
    "        UserName.append(user_name)\n",
    "    except:\n",
    "        UserName.append(\"\")\n",
    "    \n",
    "    # gathering poster's feedback count\n",
    "    try:\n",
    "        feedback_count=driver.find_element_by_xpath('//span[@class=\"-feedback-count\"]').text\n",
    "        FeedbackCount.append(feedback_count)\n",
    "    except:\n",
    "        FeedbackCount.append(\"\") \n",
    "    \n",
    "    # gathering item size, color and condition\n",
    "    try:\n",
    "        sizecolorcond=driver.find_elements_by_xpath('//h2[@class=\"listing-size sub-title\"]')\n",
    "        s_scc = \"\"\n",
    "        for part in sizecolorcond:\n",
    "            s_scc +=\" \" + part.text\n",
    "        SizeColorCond.append(s_scc)\n",
    "    except:\n",
    "        SizeColorCond.append(\"\")\n",
    "      \n",
    "    # gathering the sold price of the item\n",
    "    try:\n",
    "        item_price=driver.find_element_by_xpath('//h2[@class=\"-price _sold\"]').text\n",
    "        Price.append(item_price)\n",
    "    except:\n",
    "        Price.append(\"\")\n",
    "    \n",
    "    # gathering the description of the item\n",
    "    try:\n",
    "        item_description=driver.find_element_by_xpath('//div[@class=\"listing-description\"]').text\n",
    "        Description.append(item_description)\n",
    "    except:\n",
    "        Description.append(\"\")\n",
    "    \n",
    "    # gathering the total number of images for the item\n",
    "    try:\n",
    "        num_images=driver.find_elements_by_xpath('//div[@class=\"-image-wrapper -thumbnail\"]')\n",
    "        NumImages.append(len(num_images))\n",
    "    except:\n",
    "        NumImages.append(0)\n",
    "    \n",
    "    # gathering the category of the item\n",
    "    try:\n",
    "        item_category=driver.find_elements_by_xpath('//a[@class=\"-crumb \"]')\n",
    "        if len(item_category)>2:\n",
    "            Category.append(item_category[2].text)\n",
    "        else:\n",
    "            Category.append(item_category[1].text)          \n",
    "    except:\n",
    "        Category.append(\"\")  \n",
    "    \n",
    "    try:\n",
    "        Link.append(link)\n",
    "    except:\n",
    "        Link.append(\"\")\n",
    "\n",
    "# saving the final df\n",
    "item_desc_1 = pd.DataFrame(\n",
    "    {'username': UserName,\n",
    "     'sold_price': Price,\n",
    "     'designer' : Designer,\n",
    "     'category' : Category,\n",
    "     'description': Description,\n",
    "     'sub_title': SubTitle,\n",
    "     'image_count' : NumImages,\n",
    "     'size_color_cond': SizeColorCond,\n",
    "     'feedback_count' : FeedbackCount,\n",
    "     'link' : Link\n",
    "    })\n",
    "\n",
    "item_desc_1.to_csv('item_desc_1.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the same process is then repeated for the 5 other dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UserName = []\n",
    "Designer = []\n",
    "SubTitle = []\n",
    "SizeColorCond = []\n",
    "Category = []\n",
    "FeedbackCount = []\n",
    "Price = []\n",
    "Description = []\n",
    "NumImages = []\n",
    "Link = []\n",
    "count = 0 \n",
    "\n",
    "# opening chrome\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "driver = webdriver.Chrome(\"C:/Users/alber/Documents/chromedriver.exe\",options=chrome_options)\n",
    "driver.get(\"https://www.grailed.com/sold\")\n",
    "# timeout after 30 sec\n",
    "timeout = 30\n",
    "try:\n",
    "    WebDriverWait(driver, timeout).until(EC.visibility_of_element_located((By.XPATH, \"//div[@class='feed-item']\")))\n",
    "except TimeoutException:\n",
    "    print(\"Timed out waiting for page to load\")\n",
    "    driver.quit()\n",
    "\n",
    "for link in df_2['Link']:\n",
    "    \n",
    "    count += 1\n",
    "    \n",
    "    if count%100 == 0:\n",
    "        print(count)\n",
    "        \n",
    "    if count%5000 == 0:\n",
    "        item_desc_2 = pd.DataFrame(\n",
    "            {'username': UserName,\n",
    "             'sold_price': Price,\n",
    "             'designer' : Designer,\n",
    "             'category' : Category,\n",
    "             'description': Description,\n",
    "             'sub_title': SubTitle,\n",
    "             'image_count' : NumImages,\n",
    "             'size_color_cond': SizeColorCond,\n",
    "             'feedback_count' : FeedbackCount,\n",
    "             'link' : Link\n",
    "            })\n",
    "        \n",
    "        item_desc_2.to_csv('item_desc_2.csv')  \n",
    "    \n",
    "    try:\n",
    "        driver.get(link)\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        designer=driver.find_elements_by_xpath('//a[@class=\"designer-name\"]')\n",
    "        if len(designer)==2:\n",
    "            Designer.append(f'{designer[0].text} x {designer[1].text}')\n",
    "        else:\n",
    "            Designer.append(designer[0].text)\n",
    "    except:\n",
    "        Designer.append(\"\")\n",
    "        \n",
    "    try:\n",
    "        sub_title=driver.find_element_by_xpath('//h1[@class=\"listing-title sub-title\"]').text\n",
    "        SubTitle.append(sub_title)\n",
    "    except:\n",
    "        SubTitle.append(\"\")\n",
    "    \n",
    "    try:\n",
    "        user_name=driver.find_element_by_xpath('//span[@class=\"-username\"]').text\n",
    "        UserName.append(user_name)\n",
    "    except:\n",
    "        UserName.append(\"\")\n",
    "        \n",
    "    try:\n",
    "        feedback_count=driver.find_element_by_xpath('//span[@class=\"-feedback-count\"]').text\n",
    "        FeedbackCount.append(feedback_count)\n",
    "    except:\n",
    "        FeedbackCount.append(\"\") \n",
    "        \n",
    "    try:\n",
    "        sizecolorcond=driver.find_elements_by_xpath('//h2[@class=\"listing-size sub-title\"]')\n",
    "        s_scc = \"\"\n",
    "        for part in sizecolorcond:\n",
    "            s_scc +=\" \" + part.text\n",
    "        SizeColorCond.append(s_scc)\n",
    "    except:\n",
    "        SizeColorCond.append(\"\")\n",
    "        \n",
    "    try:\n",
    "        item_price=driver.find_element_by_xpath('//h2[@class=\"-price _sold\"]').text\n",
    "        Price.append(item_price)\n",
    "    except:\n",
    "        Price.append(\"\")\n",
    "        \n",
    "    try:\n",
    "        item_description=driver.find_element_by_xpath('//div[@class=\"listing-description\"]').text\n",
    "        Description.append(item_description)\n",
    "    except:\n",
    "        Description.append(\"\")\n",
    "        \n",
    "    try:\n",
    "        num_images=driver.find_elements_by_xpath('//div[@class=\"-image-wrapper -thumbnail\"]')\n",
    "        NumImages.append(len(num_images))\n",
    "    except:\n",
    "        NumImages.append(0)\n",
    "    \n",
    "    try:\n",
    "        item_category=driver.find_elements_by_xpath('//a[@class=\"-crumb \"]')\n",
    "        if len(item_category)>2:\n",
    "            Category.append(item_category[2].text)\n",
    "        else:\n",
    "            Category.append(item_category[1].text)          \n",
    "    except:\n",
    "        Category.append(\"\")  \n",
    "    \n",
    "    try:\n",
    "        Link.append(link)\n",
    "    except:\n",
    "        Link.append(\"\")\n",
    "        \n",
    "item_desc_2 = pd.DataFrame(\n",
    "    {'username': UserName,\n",
    "     'sold_price': Price,\n",
    "     'designer' : Designer,\n",
    "     'category' : Category,\n",
    "     'description': Description,\n",
    "     'sub_title': SubTitle,\n",
    "     'image_count' : NumImages,\n",
    "     'size_color_cond': SizeColorCond,\n",
    "     'feedback_count' : FeedbackCount,\n",
    "     'link' : Link\n",
    "    })\n",
    "\n",
    "item_desc_2.to_csv('item_desc_2.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UserName = []\n",
    "Designer = []\n",
    "SubTitle = []\n",
    "SizeColorCond = []\n",
    "Category = []\n",
    "FeedbackCount = []\n",
    "Price = []\n",
    "Description = []\n",
    "NumImages = []\n",
    "Link = []\n",
    "count = 0 \n",
    "\n",
    "# opening chrome\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "driver = webdriver.Chrome(\"C:/Users/alber/Documents/chromedriver.exe\",options=chrome_options)\n",
    "driver.get(\"https://www.grailed.com/sold\")\n",
    "# timeout after 30 sec\n",
    "timeout = 30\n",
    "try:\n",
    "    WebDriverWait(driver, timeout).until(EC.visibility_of_element_located((By.XPATH, \"//div[@class='feed-item']\")))\n",
    "except TimeoutException:\n",
    "    print(\"Timed out waiting for page to load\")\n",
    "    driver.quit()\n",
    "\n",
    "for link in df_3['Link']:\n",
    "    \n",
    "    count += 1\n",
    "    \n",
    "    if count%100 == 0:\n",
    "        print(count)\n",
    "        \n",
    "    if count%5000 == 0:\n",
    "        item_desc_3 = pd.DataFrame(\n",
    "            {'username': UserName,\n",
    "             'sold_price': Price,\n",
    "             'designer' : Designer,\n",
    "             'category' : Category,\n",
    "             'description': Description,\n",
    "             'sub_title': SubTitle,\n",
    "             'image_count' : NumImages,\n",
    "             'size_color_cond': SizeColorCond,\n",
    "             'feedback_count' : FeedbackCount,\n",
    "             'link' : Link\n",
    "            })\n",
    "        \n",
    "        item_desc_3.to_csv('item_desc_3.csv')  \n",
    "    \n",
    "    try:\n",
    "        driver.get(link)\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        designer=driver.find_elements_by_xpath('//a[@class=\"designer-name\"]')\n",
    "        if len(designer)==2:\n",
    "            Designer.append(f'{designer[0].text} x {designer[1].text}')\n",
    "        else:\n",
    "            Designer.append(designer[0].text)\n",
    "    except:\n",
    "        Designer.append(\"\")\n",
    "        \n",
    "    try:\n",
    "        sub_title=driver.find_element_by_xpath('//h1[@class=\"listing-title sub-title\"]').text\n",
    "        SubTitle.append(sub_title)\n",
    "    except:\n",
    "        SubTitle.append(\"\")\n",
    "    \n",
    "    try:\n",
    "        user_name=driver.find_element_by_xpath('//span[@class=\"-username\"]').text\n",
    "        UserName.append(user_name)\n",
    "    except:\n",
    "        UserName.append(\"\")\n",
    "        \n",
    "    try:\n",
    "        feedback_count=driver.find_element_by_xpath('//span[@class=\"-feedback-count\"]').text\n",
    "        FeedbackCount.append(feedback_count)\n",
    "    except:\n",
    "        FeedbackCount.append(\"\") \n",
    "        \n",
    "    try:\n",
    "        sizecolorcond=driver.find_elements_by_xpath('//h2[@class=\"listing-size sub-title\"]')\n",
    "        s_scc = \"\"\n",
    "        for part in sizecolorcond:\n",
    "            s_scc +=\" \" + part.text\n",
    "        SizeColorCond.append(s_scc)\n",
    "    except:\n",
    "        SizeColorCond.append(\"\")\n",
    "        \n",
    "    try:\n",
    "        item_price=driver.find_element_by_xpath('//h2[@class=\"-price _sold\"]').text\n",
    "        Price.append(item_price)\n",
    "    except:\n",
    "        Price.append(\"\")\n",
    "        \n",
    "    try:\n",
    "        item_description=driver.find_element_by_xpath('//div[@class=\"listing-description\"]').text\n",
    "        Description.append(item_description)\n",
    "    except:\n",
    "        Description.append(\"\")\n",
    "        \n",
    "    try:\n",
    "        num_images=driver.find_elements_by_xpath('//div[@class=\"-image-wrapper -thumbnail\"]')\n",
    "        NumImages.append(len(num_images))\n",
    "    except:\n",
    "        NumImages.append(0)\n",
    "    \n",
    "    try:\n",
    "        item_category=driver.find_elements_by_xpath('//a[@class=\"-crumb \"]')\n",
    "        if len(item_category)>2:\n",
    "            Category.append(item_category[2].text)\n",
    "        else:\n",
    "            Category.append(item_category[1].text)          \n",
    "    except:\n",
    "        Category.append(\"\")  \n",
    "    \n",
    "    try:\n",
    "        Link.append(link)\n",
    "    except:\n",
    "        Link.append(\"\")\n",
    "        \n",
    "item_desc_3 = pd.DataFrame(\n",
    "    {'username': UserName,\n",
    "     'sold_price': Price,\n",
    "     'designer' : Designer,\n",
    "     'category' : Category,\n",
    "     'description': Description,\n",
    "     'sub_title': SubTitle,\n",
    "     'image_count' : NumImages,\n",
    "     'size_color_cond': SizeColorCond,\n",
    "     'feedback_count' : FeedbackCount,\n",
    "     'link' : Link\n",
    "    })\n",
    "\n",
    "item_desc_3.to_csv('item_desc_3.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UserName = []\n",
    "Designer = []\n",
    "SubTitle = []\n",
    "SizeColorCond = []\n",
    "Category = []\n",
    "FeedbackCount = []\n",
    "Price = []\n",
    "Description = []\n",
    "NumImages = []\n",
    "Link = []\n",
    "count = 0 \n",
    "\n",
    "# opening chrome\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "driver = webdriver.Chrome(\"C:/Users/alber/Documents/chromedriver.exe\",options=chrome_options)\n",
    "driver.get(\"https://www.grailed.com/sold\")\n",
    "# timeout after 30 sec\n",
    "timeout = 30\n",
    "try:\n",
    "    WebDriverWait(driver, timeout).until(EC.visibility_of_element_located((By.XPATH, \"//div[@class='feed-item']\")))\n",
    "except TimeoutException:\n",
    "    print(\"Timed out waiting for page to load\")\n",
    "    driver.quit()\n",
    "\n",
    "for link in df_4['Link']:\n",
    "    \n",
    "    count += 1\n",
    "    \n",
    "    if count%100 == 0:\n",
    "        print(count)\n",
    "        \n",
    "    if count%5000 == 0:\n",
    "        item_desc_4 = pd.DataFrame(\n",
    "            {'username': UserName,\n",
    "             'sold_price': Price,\n",
    "             'designer' : Designer,\n",
    "             'category' : Category,\n",
    "             'description': Description,\n",
    "             'sub_title': SubTitle,\n",
    "             'image_count' : NumImages,\n",
    "             'size_color_cond': SizeColorCond,\n",
    "             'feedback_count' : FeedbackCount,\n",
    "             'link' : Link\n",
    "            })\n",
    "        \n",
    "        item_desc_4.to_csv('item_desc_4.csv')  \n",
    "    \n",
    "    try:\n",
    "        driver.get(link)\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        designer=driver.find_elements_by_xpath('//a[@class=\"designer-name\"]')\n",
    "        if len(designer)==2:\n",
    "            Designer.append(f'{designer[0].text} x {designer[1].text}')\n",
    "        else:\n",
    "            Designer.append(designer[0].text)\n",
    "    except:\n",
    "        Designer.append(\"\")\n",
    "        \n",
    "    try:\n",
    "        sub_title=driver.find_element_by_xpath('//h1[@class=\"listing-title sub-title\"]').text\n",
    "        SubTitle.append(sub_title)\n",
    "    except:\n",
    "        SubTitle.append(\"\")\n",
    "    \n",
    "    try:\n",
    "        user_name=driver.find_element_by_xpath('//span[@class=\"-username\"]').text\n",
    "        UserName.append(user_name)\n",
    "    except:\n",
    "        UserName.append(\"\")\n",
    "        \n",
    "    try:\n",
    "        feedback_count=driver.find_element_by_xpath('//span[@class=\"-feedback-count\"]').text\n",
    "        FeedbackCount.append(feedback_count)\n",
    "    except:\n",
    "        FeedbackCount.append(\"\") \n",
    "        \n",
    "    try:\n",
    "        sizecolorcond=driver.find_elements_by_xpath('//h2[@class=\"listing-size sub-title\"]')\n",
    "        s_scc = \"\"\n",
    "        for part in sizecolorcond:\n",
    "            s_scc +=\" \" + part.text\n",
    "        SizeColorCond.append(s_scc)\n",
    "    except:\n",
    "        SizeColorCond.append(\"\")\n",
    "        \n",
    "    try:\n",
    "        item_price=driver.find_element_by_xpath('//h2[@class=\"-price _sold\"]').text\n",
    "        Price.append(item_price)\n",
    "    except:\n",
    "        Price.append(\"\")\n",
    "        \n",
    "    try:\n",
    "        item_description=driver.find_element_by_xpath('//div[@class=\"listing-description\"]').text\n",
    "        Description.append(item_description)\n",
    "    except:\n",
    "        Description.append(\"\")\n",
    "        \n",
    "    try:\n",
    "        num_images=driver.find_elements_by_xpath('//div[@class=\"-image-wrapper -thumbnail\"]')\n",
    "        NumImages.append(len(num_images))\n",
    "    except:\n",
    "        NumImages.append(0)\n",
    "    \n",
    "    try:\n",
    "        item_category=driver.find_elements_by_xpath('//a[@class=\"-crumb \"]')\n",
    "        if len(item_category)>2:\n",
    "            Category.append(item_category[2].text)\n",
    "        else:\n",
    "            Category.append(item_category[1].text)          \n",
    "    except:\n",
    "        Category.append(\"\")  \n",
    "    \n",
    "    try:\n",
    "        Link.append(link)\n",
    "    except:\n",
    "        Link.append(\"\")\n",
    "        \n",
    "item_desc_4 = pd.DataFrame(\n",
    "    {'username': UserName,\n",
    "     'sold_price': Price,\n",
    "     'designer' : Designer,\n",
    "     'category' : Category,\n",
    "     'description': Description,\n",
    "     'sub_title': SubTitle,\n",
    "     'image_count' : NumImages,\n",
    "     'size_color_cond': SizeColorCond,\n",
    "     'feedback_count' : FeedbackCount,\n",
    "     'link' : Link\n",
    "    })\n",
    "\n",
    "item_desc_4.to_csv('item_desc_4.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UserName = []\n",
    "Designer = []\n",
    "SubTitle = []\n",
    "SizeColorCond = []\n",
    "Category = []\n",
    "FeedbackCount = []\n",
    "Price = []\n",
    "Description = []\n",
    "NumImages = []\n",
    "Link = []\n",
    "count = 0 \n",
    "\n",
    "# opening chrome\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "driver = webdriver.Chrome(\"C:/Users/alber/Documents/chromedriver.exe\",options=chrome_options)\n",
    "driver.get(\"https://www.grailed.com/sold\")\n",
    "# timeout after 30 sec\n",
    "timeout = 30\n",
    "try:\n",
    "    WebDriverWait(driver, timeout).until(EC.visibility_of_element_located((By.XPATH, \"//div[@class='feed-item']\")))\n",
    "except TimeoutException:\n",
    "    print(\"Timed out waiting for page to load\")\n",
    "    driver.quit()\n",
    "\n",
    "for link in df_5['Link']:\n",
    "    \n",
    "    count += 1\n",
    "    \n",
    "    if count%100 == 0:\n",
    "        print(count)\n",
    "        \n",
    "    if count%5000 == 0:\n",
    "        item_desc_5 = pd.DataFrame(\n",
    "            {'username': UserName,\n",
    "             'sold_price': Price,\n",
    "             'designer' : Designer,\n",
    "             'category' : Category,\n",
    "             'description': Description,\n",
    "             'sub_title': SubTitle,\n",
    "             'image_count' : NumImages,\n",
    "             'size_color_cond': SizeColorCond,\n",
    "             'feedback_count' : FeedbackCount,\n",
    "             'link' : Link\n",
    "            })\n",
    "        \n",
    "        item_desc_5.to_csv('item_desc_5.csv')  \n",
    "    \n",
    "    try:\n",
    "        driver.get(link)\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        designer=driver.find_elements_by_xpath('//a[@class=\"designer-name\"]')\n",
    "        if len(designer)==2:\n",
    "            Designer.append(f'{designer[0].text} x {designer[1].text}')\n",
    "        else:\n",
    "            Designer.append(designer[0].text)\n",
    "    except:\n",
    "        Designer.append(\"\")\n",
    "        \n",
    "    try:\n",
    "        sub_title=driver.find_element_by_xpath('//h1[@class=\"listing-title sub-title\"]').text\n",
    "        SubTitle.append(sub_title)\n",
    "    except:\n",
    "        SubTitle.append(\"\")\n",
    "    \n",
    "    try:\n",
    "        user_name=driver.find_element_by_xpath('//span[@class=\"-username\"]').text\n",
    "        UserName.append(user_name)\n",
    "    except:\n",
    "        UserName.append(\"\")\n",
    "        \n",
    "    try:\n",
    "        feedback_count=driver.find_element_by_xpath('//span[@class=\"-feedback-count\"]').text\n",
    "        FeedbackCount.append(feedback_count)\n",
    "    except:\n",
    "        FeedbackCount.append(\"\") \n",
    "        \n",
    "    try:\n",
    "        sizecolorcond=driver.find_elements_by_xpath('//h2[@class=\"listing-size sub-title\"]')\n",
    "        s_scc = \"\"\n",
    "        for part in sizecolorcond:\n",
    "            s_scc +=\" \" + part.text\n",
    "        SizeColorCond.append(s_scc)\n",
    "    except:\n",
    "        SizeColorCond.append(\"\")\n",
    "        \n",
    "    try:\n",
    "        item_price=driver.find_element_by_xpath('//h2[@class=\"-price _sold\"]').text\n",
    "        Price.append(item_price)\n",
    "    except:\n",
    "        Price.append(\"\")\n",
    "        \n",
    "    try:\n",
    "        item_description=driver.find_element_by_xpath('//div[@class=\"listing-description\"]').text\n",
    "        Description.append(item_description)\n",
    "    except:\n",
    "        Description.append(\"\")\n",
    "        \n",
    "    try:\n",
    "        num_images=driver.find_elements_by_xpath('//div[@class=\"-image-wrapper -thumbnail\"]')\n",
    "        NumImages.append(len(num_images))\n",
    "    except:\n",
    "        NumImages.append(0)\n",
    "    \n",
    "    try:\n",
    "        item_category=driver.find_elements_by_xpath('//a[@class=\"-crumb \"]')\n",
    "        if len(item_category)>2:\n",
    "            Category.append(item_category[2].text)\n",
    "        else:\n",
    "            Category.append(item_category[1].text)          \n",
    "    except:\n",
    "        Category.append(\"\")  \n",
    "    \n",
    "    try:\n",
    "        Link.append(link)\n",
    "    except:\n",
    "        Link.append(\"\")\n",
    "        \n",
    "item_desc_5 = pd.DataFrame(\n",
    "    {'username': UserName,\n",
    "     'sold_price': Price,\n",
    "     'designer' : Designer,\n",
    "     'category' : Category,\n",
    "     'description': Description,\n",
    "     'sub_title': SubTitle,\n",
    "     'image_count' : NumImages,\n",
    "     'size_color_cond': SizeColorCond,\n",
    "     'feedback_count' : FeedbackCount,\n",
    "     'link' : Link\n",
    "    })\n",
    "\n",
    "item_desc_5.to_csv('item_desc_5.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UserName = []\n",
    "Designer = []\n",
    "SubTitle = []\n",
    "SizeColorCond = []\n",
    "Category = []\n",
    "FeedbackCount = []\n",
    "Price = []\n",
    "Description = []\n",
    "NumImages = []\n",
    "Link = []\n",
    "count = 0 \n",
    "\n",
    "# opening chrome\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "driver = webdriver.Chrome(\"C:/Users/alber/Documents/chromedriver.exe\",options=chrome_options)\n",
    "driver.get(\"https://www.grailed.com/sold\")\n",
    "# timeout after 30 sec\n",
    "timeout = 30\n",
    "try:\n",
    "    WebDriverWait(driver, timeout).until(EC.visibility_of_element_located((By.XPATH, \"//div[@class='feed-item']\")))\n",
    "except TimeoutException:\n",
    "    print(\"Timed out waiting for page to load\")\n",
    "    driver.quit()\n",
    "\n",
    "for link in df_6['Link']:\n",
    "    \n",
    "    count += 1\n",
    "    \n",
    "    if count%100 == 0:\n",
    "        print(count)\n",
    "        \n",
    "    if count%5000 == 0:\n",
    "        item_desc_6 = pd.DataFrame(\n",
    "            {'username': UserName,\n",
    "             'sold_price': Price,\n",
    "             'designer' : Designer,\n",
    "             'category' : Category,\n",
    "             'description': Description,\n",
    "             'sub_title': SubTitle,\n",
    "             'image_count' : NumImages,\n",
    "             'size_color_cond': SizeColorCond,\n",
    "             'feedback_count' : FeedbackCount,\n",
    "             'link' : Link\n",
    "            })\n",
    "        \n",
    "        item_desc_6.to_csv('item_desc_6.csv')  \n",
    "    \n",
    "    try:\n",
    "        driver.get(link)\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        designer=driver.find_elements_by_xpath('//a[@class=\"designer-name\"]')\n",
    "        if len(designer)==2:\n",
    "            Designer.append(f'{designer[0].text} x {designer[1].text}')\n",
    "        else:\n",
    "            Designer.append(designer[0].text)\n",
    "    except:\n",
    "        Designer.append(\"\")\n",
    "        \n",
    "    try:\n",
    "        sub_title=driver.find_element_by_xpath('//h1[@class=\"listing-title sub-title\"]').text\n",
    "        SubTitle.append(sub_title)\n",
    "    except:\n",
    "        SubTitle.append(\"\")\n",
    "    \n",
    "    try:\n",
    "        user_name=driver.find_element_by_xpath('//span[@class=\"-username\"]').text\n",
    "        UserName.append(user_name)\n",
    "    except:\n",
    "        UserName.append(\"\")\n",
    "        \n",
    "    try:\n",
    "        feedback_count=driver.find_element_by_xpath('//span[@class=\"-feedback-count\"]').text\n",
    "        FeedbackCount.append(feedback_count)\n",
    "    except:\n",
    "        FeedbackCount.append(\"\") \n",
    "        \n",
    "    try:\n",
    "        sizecolorcond=driver.find_elements_by_xpath('//h2[@class=\"listing-size sub-title\"]')\n",
    "        s_scc = \"\"\n",
    "        for part in sizecolorcond:\n",
    "            s_scc +=\" \" + part.text\n",
    "        SizeColorCond.append(s_scc)\n",
    "    except:\n",
    "        SizeColorCond.append(\"\")\n",
    "        \n",
    "    try:\n",
    "        item_price=driver.find_element_by_xpath('//h2[@class=\"-price _sold\"]').text\n",
    "        Price.append(item_price)\n",
    "    except:\n",
    "        Price.append(\"\")\n",
    "        \n",
    "    try:\n",
    "        item_description=driver.find_element_by_xpath('//div[@class=\"listing-description\"]').text\n",
    "        Description.append(item_description)\n",
    "    except:\n",
    "        Description.append(\"\")\n",
    "        \n",
    "    try:\n",
    "        num_images=driver.find_elements_by_xpath('//div[@class=\"-image-wrapper -thumbnail\"]')\n",
    "        NumImages.append(len(num_images))\n",
    "    except:\n",
    "        NumImages.append(0)\n",
    "    \n",
    "    try:\n",
    "        item_category=driver.find_elements_by_xpath('//a[@class=\"-crumb \"]')\n",
    "        if len(item_category)>2:\n",
    "            Category.append(item_category[2].text)\n",
    "        else:\n",
    "            Category.append(item_category[1].text)          \n",
    "    except:\n",
    "        Category.append(\"\")  \n",
    "    \n",
    "    try:\n",
    "        Link.append(link)\n",
    "    except:\n",
    "        Link.append(\"\")\n",
    "        \n",
    "item_desc_6 = pd.DataFrame(\n",
    "    {'username': UserName,\n",
    "     'sold_price': Price,\n",
    "     'designer' : Designer,\n",
    "     'category' : Category,\n",
    "     'description': Description,\n",
    "     'sub_title': SubTitle,\n",
    "     'image_count' : NumImages,\n",
    "     'size_color_cond': SizeColorCond,\n",
    "     'feedback_count' : FeedbackCount,\n",
    "     'link' : Link\n",
    "    })\n",
    "\n",
    "item_desc_6.to_csv('item_desc_6.csv') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
